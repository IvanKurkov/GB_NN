{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0hyWYiPqLdez"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ba0e617f649c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2DTranspose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Conv2DTranspose, concatenate, Activation, MaxPooling2D, Conv2D, BatchNormalization\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import utils\n",
    "from google.colab import files\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import VGG16, EfficientNetB0, ResNet101, DenseNet121\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Это наша метрика на Tensorflow\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    return (2. * tf.math.reduce_sum(y_true * y_pred) + 1.) / (tf.math.reduce_sum(y_true) + tf.math.reduce_sum(y_pred) + 1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQHnXfaof51T"
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxHD9MO-sM_u"
   },
   "source": [
    "Загружаем картинки для сегментации (имена почти одинаковые: изображение.png - это сам кадр и изображение (1).png - это разметка)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2DoDDp_bdWd"
   },
   "source": [
    "Вот так загружаем с локального диска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "po4700QUSigV"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "# uploaded = files.upload()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X4fDh8rBxcmk"
   },
   "outputs": [],
   "source": [
    "#!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9F-kC0Ctbp6y"
   },
   "source": [
    "Открываем архив (это зависит от архива)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fHFJLVjuYqPz"
   },
   "outputs": [],
   "source": [
    "#!pip install rarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HmEtY7SRYy-w"
   },
   "outputs": [],
   "source": [
    "#import rarfile\n",
    "\n",
    "#rf = rarfile.RarFile(\"small_segment.rar\")\n",
    "#for f in rf.infolist():\n",
    "#    print(f.filename, f.file_size)\n",
    "#    if f.filename == \"README\":\n",
    "#        print(rf.read(f))\n",
    "#rf.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZlXgfwO3ZOee"
   },
   "outputs": [],
   "source": [
    "#!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieVpYyeOb5Oc"
   },
   "source": [
    "А вот так загрузим картинки с Гугл Диска (делаем только один вариант загрузки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d-nXzGlaQgtX",
    "outputId": "b81f1cb1-9d11-41b6-d524-770f2bd1ab6d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLO1-atVcJk6"
   },
   "source": [
    "Прочитаем списки наших файлов (проверить идентичность, если имена одинаковые или собрать порядок чтения любым доступным способом)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFwlliF3ccPr"
   },
   "source": [
    "Задаю маршрут для чтения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UHPvMcZQDdw4"
   },
   "outputs": [],
   "source": [
    "PAHT_label = '/gdrive/My Drive/нейросети Ноутбуки для вебинаров Корлякова/урок 6/labels/'\n",
    "PAHT_image = '/gdrive/My Drive/нейросети Ноутбуки для вебинаров Корлякова/урок 6/images/'\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78tWHOY48hCf"
   },
   "source": [
    "Читаем имена файлов из рабочего каталога"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxJvd9BQSrnv"
   },
   "outputs": [],
   "source": [
    "import os, fnmatch\n",
    "imag = os.listdir(PAHT_label)\n",
    "imag_label = os.listdir(PAHT_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "STRR6fpBCNVu",
    "outputId": "f866550c-a7a4-4046-a669-e99867300f1e"
   },
   "outputs": [],
   "source": [
    "imag,imag_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cf2NRmzZ4x0g"
   },
   "source": [
    "#Загружаем и уменьшаем картинки\n",
    "\n",
    "можно обойтись исходным рахзмером или взять другой\n",
    "\n",
    "ВАЖНО - размер по обеим сторонам должен делиться на 2 несколько раз (сколько будет сжатий кадра)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MRDvv0-DQHwT"
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "segments = []\n",
    "image_size = (200,600)\n",
    "for i_name in imag:\n",
    "  images.append(image.load_img(PAHT_image+i_name ,target_size = image_size))\n",
    "  segments.append(image.load_img(PAHT_label+i_name, target_size = image_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVBSnDTZc4Ut"
   },
   "source": [
    "Посмотрели на входные кадры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "_A0a9pZxQeQM",
    "outputId": "f2a50370-8caa-4ed7-f1e3-8686df6cac40"
   },
   "outputs": [],
   "source": [
    "plt.imshow(images[0].convert('RGBA'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1P8JqZzc9B9"
   },
   "source": [
    "Посмотрим на цели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "tzRS1IHyRIQz",
    "outputId": "766d4ffe-e9cf-41f6-91c7-cf5b567edaf6"
   },
   "outputs": [],
   "source": [
    "plt.imshow(segments[0].convert('RGBA'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PBaLEFrsVdA"
   },
   "source": [
    "#Создаём обучающую выборку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "198szSA6dBO9"
   },
   "source": [
    "Собираем входные примеры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cllzV4CWQkCX"
   },
   "outputs": [],
   "source": [
    "xTrain_Test = []\n",
    "\n",
    "for img in images:\n",
    "  x = image.img_to_array(img)\n",
    "  xTrain_Test.append(x)\n",
    "\n",
    "xTrain_Test = np.array(xTrain_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bDxcAnq7QtSp",
    "outputId": "2be41c11-95a2-4b0f-834f-8e3993c6cdf2"
   },
   "outputs": [],
   "source": [
    "print(xTrain_Test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pszQXMDwsZKg"
   },
   "source": [
    "Порстроим цвета , воспринимаемого диапазона для сегментированной картинки - это результат разметки, которую принесет разметчик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwAQ6xhuvdz-"
   },
   "source": [
    "Color Coding:\n",
    "\n",
    "Name\t(r,g,b)\t    7-Class mapping\n",
    "\n",
    "Car\t  ( 0, 0,255)\tObject\n",
    "\n",
    "Road\t(255, 0, 0)\tRoad\n",
    "\n",
    "Mark\t(255,255, 0)\tRoad\n",
    "\n",
    "Building\t( 0,255, 0)\tBuilding\n",
    "\n",
    "Sidewalk\t(255, 0,255)\tRoad\n",
    "\n",
    "Tree/Bush\t( 0,255,255)\tTree/Bush\n",
    "\n",
    "Pole\t(255, 0,153)\tSign/Pole\n",
    "\n",
    "Sign\t(153, 0,255)\tSign/Pole\n",
    "\n",
    "Person\t( 0,153,255)\tObject\n",
    "\n",
    "Wall\t(153,255, 0)\tBuilding\n",
    "\n",
    "Sky\t(255,153, 0)\tSky\n",
    "\n",
    "Curb\t( 0,255,153)\tRoad\n",
    "\n",
    "Grass/Dirt\t( 0,153,153)\tGrass/Dirt\n",
    "\n",
    "Void\t( 0, 0, 0)\tVoid\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCKKm9O0dRKA"
   },
   "source": [
    "Делаем конвертер в one-hot_encoding для выходных примеров\n",
    "\n",
    "  - каждому классу (цвету) ставим в соответствие свою карту ответов y_cat, где 1 , если цвет этого пикселя равен номеру карты и 0 в противном случае\n",
    "  - для визуализации строим карту цветов y_ind, где пиксель содержит номер цвета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "L-tB6iMSvcy3",
    "outputId": "4f40499e-4fe7-4aa7-9152-870fbd3930e4"
   },
   "outputs": [],
   "source": [
    "def Color2index(y):\n",
    "  #y - входное изображение разметки (УхХхС - цветное )\n",
    "  # карту цветов y_ind\n",
    "  # карту ответов one-hot-encoding y_cat\n",
    "\n",
    "  # список актуальных цветов разметки\n",
    "  arr_col=[[0,0,255],[255,0,0],[255,255,0],[0,255,0],[255,0,255],[0,255,255],[255,0,153],[153,0,255],[0,153,255],[153,255,0],[255,153,0],[0,255,153],[0,153,153],[0,0,0]]\n",
    "  y_ind = np.zeros((y.shape[0],y.shape[1]))\n",
    "  y_cat = np.zeros((y.shape[0],y.shape[1], len(arr_col)))\n",
    "  i = 1\n",
    "  for i_color in arr_col:\n",
    "    #найдем все точки цвета i_color\n",
    "    ind_i = np.where((y[:,:,0] == i_color[0]) & (y[:,:,1] == i_color[1]) & (y[:,:,2] == i_color[2]))\n",
    "    \n",
    "    y_ind[ind_i[0],ind_i[1]] = i\n",
    "    y_cat[ind_i[0],ind_i[1], i-1] = 1 \n",
    "    i += 1\n",
    "  \n",
    "  return y_cat, y_ind, i-1\n",
    "cat_yi,ind_yi,h = Color2index(image.img_to_array(segments[0]))\n",
    "plt.imshow(ind_yi.astype(float)/h)\n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpZidIlu9Ahd"
   },
   "source": [
    "Проверяем максимальное значение слоя 1 (по нашей схеме должна быть 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mqrggZrxYgo2",
    "outputId": "435ece80-5ffc-4f3d-bb6c-3a06ca800152"
   },
   "outputs": [],
   "source": [
    "np.max(cat_yi[:,:,1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9iJI7-KF-ok5"
   },
   "source": [
    "Посмотрим на маленький фрагмент карты ответов для сети "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "iR9EQAKmxM3T",
    "outputId": "06217355-9b87-4f7a-cd9a-596e071325cf"
   },
   "outputs": [],
   "source": [
    "plt.imshow(cat_yi[:100,:100,3])\n",
    "plt.title('out map on class 3 ')\n",
    "plt.show()\n",
    "plt.imshow(xTrain_Test[0,:100,:100,:]/255)\n",
    "plt.title('input image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DM25LwB2_DeS"
   },
   "source": [
    "Оценим размер карты ответа:\n",
    "  - число каналов равно числу классов\n",
    "  - размер карты равер размеру картинки входа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tX3KnPJP8nAz",
    "outputId": "b0b25e43-30eb-4abe-b0c7-bcf0818983bf"
   },
   "outputs": [],
   "source": [
    "cat_yi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDVilj2bsfnh"
   },
   "source": [
    "Сегментированную картинку в  One hot encoding (разметка на 14 классов)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZo7ZyPZRUG4"
   },
   "outputs": [],
   "source": [
    "yTrain_Test = []\n",
    "\n",
    "for seg in segments:\n",
    "  y_cat,_,_ = Color2index(image.img_to_array(seg))\n",
    "  yTrain_Test.append(y_cat)\n",
    "\n",
    "yTrain_Test = np.array(yTrain_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2xkJjfRjfME4",
    "outputId": "51f41f00-cf5d-4efd-b647-9b6801ff8dd8"
   },
   "outputs": [],
   "source": [
    "print(yTrain_Test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "by1vcel-qCTY",
    "outputId": "5f2b07fd-1585-4292-d6de-1722c304da2d"
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.imshow(segments[n].convert('RGBA'))\n",
    "plt.show()\n",
    "img = yTrain_Test[n][:,:,n]\n",
    "plt.imshow(img.astype(float))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRdgaYD7dgsX"
   },
   "source": [
    "Делим на тест и трейн по числу N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KAyodVMK2Sus"
   },
   "outputs": [],
   "source": [
    "N = 15\n",
    "yTrain = yTrain_Test[:N,:,:,:]\n",
    "xTrain = xTrain_Test[:N,:,:,:]\n",
    "\n",
    "yTest = yTrain_Test[N:,:,:,:]\n",
    "xTest = xTrain_Test[N:,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WguT86Hf6UBL",
    "outputId": "714c2ee6-b718-4f57-f209-13129dd191f8"
   },
   "outputs": [],
   "source": [
    "yTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7WnRwpvSXQkq",
    "outputId": "c660bdd0-114c-4b1c-c1ca-1f74897e56ca"
   },
   "outputs": [],
   "source": [
    "print(xTrain.shape)\n",
    "print(yTrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FC9VX4zsnJa"
   },
   "source": [
    "#Создаём и обучаем U-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMAJIIMvMn49"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4u9ZnvOF3h9p"
   },
   "source": [
    "**Unet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-n-ivxFLKOF"
   },
   "outputs": [],
   "source": [
    "def Unet(num_classes = 14, input_shape= (200, 600, 3)):\n",
    "  #num_classes = 14, - число классов ответа\n",
    "  #input_shape= (200, 600, 3) - размер входной картинки\n",
    "\n",
    "  #model - выходная модель\n",
    "\n",
    "    img_input = Input(input_shape) # вход модели\n",
    "\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), padding='same', name='block1_conv1')(img_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same', name='block1_conv2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # запомним тензор для переноса\n",
    "    block_1_out = Activation('relu')(x)\n",
    "\n",
    "    x = MaxPooling2D()(block_1_out) # 100x300\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), padding='same', name='block2_conv1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same', name='block2_conv2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # запомним тензор для переноса\n",
    "    block_2_out = Activation('relu')(x)\n",
    "\n",
    "    x = MaxPooling2D()(block_2_out) # 50x150\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv3')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # запомним тензор для переноса\n",
    "    block_3_out = Activation('relu')(x)\n",
    "\n",
    "    x = MaxPooling2D()(block_3_out) #25x75\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv3')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # запомним тензор для переноса\n",
    "    block_4_out = Activation('relu')(x)\n",
    "\n",
    "    #x = MaxPooling2D()(block_4_out)\n",
    "\n",
    "    # Block 5\n",
    "    #x = Conv2D(512, (3, 3), padding='same', name='block5_conv1')(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = Activation('relu')(x)\n",
    "\n",
    "    #x = Conv2D(512, (3, 3), padding='same', name='block5_conv2')(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = Activation('relu')(x)\n",
    "\n",
    "    #x = Conv2D(512, (3, 3), padding='same', name='block5_conv3')(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "    # Load pretrained weights.\n",
    "    #for_pretrained_weight = MaxPooling2D()(x)\n",
    "    #vgg16 = Model(img_input, for_pretrained_weight)\n",
    "    #vgg16.load_weights('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', by_name=True)\n",
    "\n",
    "    # UP 1\n",
    "    #x = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = Activation('relu')(x)\n",
    "\n",
    "    #x = concatenate([x, block_4_out])\n",
    "    #x = Conv2D(512, (3, 3), padding='same')(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = Activation('relu')(x)\n",
    "\n",
    "    #x = Conv2D(512, (3, 3), padding='same')(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = Activation('relu')(x)\n",
    "\n",
    "    # UP 2\n",
    "    x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x) #50x150\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # добавили перенос из понижаюшего плеча\n",
    "    x = concatenate([x, block_3_out])\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # UP 3\n",
    "    x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x) # 100x300\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # добавили перенос из понижаюшего плеча\n",
    "    x = concatenate([x, block_2_out])\n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # UP 4\n",
    "    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x) # 200x600\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # добавили перенос из понижаюшего плеча\n",
    "    x = concatenate([x, block_1_out])\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # слой классификатор\n",
    "    x = Conv2D(num_classes, (3, 3), activation='softmax', padding='same')(x)\n",
    "\n",
    "    model = Model(img_input, x)\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=[dice_coef])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fWX4t-WWUmrv",
    "outputId": "ae6c9eb9-b906-4e83-ce36-fb7640320d3f"
   },
   "outputs": [],
   "source": [
    "modelC = Unet(14, (200, 600, 3))\n",
    "\n",
    "plot_model(modelC, to_file='modelC.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDOJPJ93ALsX"
   },
   "source": [
    "Обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eFlktpNPRtVC",
    "outputId": "0db8984c-325c-48a0-8838-0c25ae9337df"
   },
   "outputs": [],
   "source": [
    "\n",
    "history = modelC.fit(xTrain, yTrain, epochs=10, batch_size=1, validation_data=(xTrain, yTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "nWjYF9nt5Wr-",
    "outputId": "43c3ef5d-5102-4d4f-97df-d14460cc609a"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_dice_coef'],label = 'test')\n",
    "plt.plot(history.history['dice_coef'],label='train')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('dice_coef')\n",
    "plt.grid()\n",
    "plt.title('history of train and val')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FN8siDYPpNxJ",
    "outputId": "f6f9d77e-5d71-44c3-84a7-dc22bcdb70ca"
   },
   "outputs": [],
   "source": [
    "history = modelC.fit(xTrain, yTrain, epochs=2, batch_size=1, validation_data=(xTest, yTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbmMdL9HA_Zb"
   },
   "source": [
    "Тест модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E374m5yTggzT",
    "outputId": "7ed6da5f-364d-45c2-f9f0-c3ac9394b618"
   },
   "outputs": [],
   "source": [
    "pred = modelC.predict(xTest)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "zzn9HP3x599Y",
    "outputId": "f486d79f-c139-4146-ffed-5ba335da8315"
   },
   "outputs": [],
   "source": [
    "n = 0\n",
    "class_ =5\n",
    "plt.imshow(images[N+n].convert('RGBA'))\n",
    "plt.title('входной кадр')\n",
    "plt.show()\n",
    "plt.imshow(segments[N+n].convert('RGBA'))\n",
    "plt.title('целевая разметка')\n",
    "plt.show()\n",
    "img = yTest[n][:,:,class_]\n",
    "plt.imshow(img.astype(float))\n",
    "plt.title('целевая разметка класс: '+str(class_))\n",
    "plt.show()\n",
    "img = pred[n][:,:,class_]\n",
    "plt.imshow(img.astype(float))\n",
    "plt.title('предиктивная разметка класс: '+str(class_))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxqHWCfm93PV"
   },
   "source": [
    "**Претренированная  Unet**\n",
    "\n",
    "посмотрим на модели для переноса обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v9mnto6I8Emn",
    "outputId": "aeb42109-845f-465b-ec55-6777281be917"
   },
   "outputs": [],
   "source": [
    " pre_trained_model = VGG16(input_shape=xTest.shape[1:], include_top=False, weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5A1qzZDs9Zgg",
    "outputId": "89043980-8079-4402-94dc-97a269cd6204"
   },
   "outputs": [],
   "source": [
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBEqagS-BT22"
   },
   "source": [
    "Напишем несколько функций для упрощения сборки модели\n",
    "  - функцию увеличения разрешения bloc_transpose\n",
    "  - функцию генерации модели из претернированной unet_pre_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6oLXqtJQ5Lqw"
   },
   "outputs": [],
   "source": [
    "def bloc_transpose(x,block_out, numb_filter = [256,128]):\n",
    "  #x, - input tensor\n",
    "  #block_out, - scip tensor\n",
    "  #numb_filter = [256,128] - number of kernel in layers\n",
    "  x = concatenate([x, block_out])\n",
    "  x = Conv2D(numb_filter[0], (3, 3), padding='same')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "\n",
    "  x = Conv2D(numb_filter[0], (3, 3), padding='same')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "\n",
    "  # UP \n",
    "  x = Conv2DTranspose(numb_filter[1], (2, 2), strides=(2, 2), padding='same')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FW_ozrde94oN"
   },
   "outputs": [],
   "source": [
    "pre_trained_model = VGG16(input_shape=(200, 600, 3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "def unet_pre_train(num_classes = 13, input_shape= (200, 600, 3), pre_trained_model = None, pretrain_out = 13,list_bloc = [10,6,3]):    \n",
    "    if pre_trained_model != None:\n",
    "      for layer in pre_trained_model.layers[:len(pre_trained_model.layers)]:\n",
    "        layer.trainable = False\n",
    "      x = pre_trained_model.layers[pretrain_out].output # конец сверток\n",
    "      block_out = [pre_trained_model.layers[i].output for i in list_bloc]\n",
    "     \n",
    "      img_input = pre_trained_model.inputs\n",
    "      print(block_out[0])\n",
    "      # первое уменьшение размера\n",
    "    else:\n",
    "      return None  \n",
    "    # UP 1\n",
    "\n",
    "    # добавили перенос из понижаюшего плеча VGG16\n",
    "    for i,block_i in enumerate(block_out):\n",
    "      x = bloc_transpose(x, block_i, numb_filter = [256// 2**i,128// 2**i])\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(num_classes, (3, 3), activation='softmax', padding='same')(x)\n",
    "\n",
    "    model = Model(img_input, x)\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=[dice_coef])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mypQE59dVCE4",
    "outputId": "bc6d492c-31a8-4952-d138-263e70010d37"
   },
   "outputs": [],
   "source": [
    "modelU = unet_pre_train(num_classes = 14, input_shape= (200, 600, 3), pre_trained_model = pre_trained_model)\n",
    "\n",
    "plot_model(modelU, to_file='modelU.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hyYDnJAkAaV-"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1xzKqyZFDPF"
   },
   "source": [
    "Пишем свой обратный вызов. Он только для визуализации результатов работы эпохи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xtUQn6ec8jJM"
   },
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs = None):\n",
    "    #clear_output(wait=True)\n",
    "    Ipred = self.model(xTest[:1])\n",
    "\n",
    "    k = Ipred.shape[3]\n",
    "    if k>4:\n",
    "      k = 4\n",
    "    print('Predict')\n",
    "    plt.figure(figsize = (5*k,3))\n",
    "    plt.ylabel('predict')\n",
    "    for i in range(k):\n",
    "      plt.subplot(1,k+1,i+1)\n",
    "      plt.imshow(Ipred[0,:,:,i])\n",
    "    \n",
    "    plt.show() \n",
    "    print('True') \n",
    "    plt.figure(figsize = (5*k,3))\n",
    "    plt.ylabel('predict')\n",
    "    for i in range(k):\n",
    "      plt.subplot(1,k+1,i+1)\n",
    "      plt.imshow(yTest[0,:,:,i])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bHTtcdi1ETj0",
    "outputId": "761bafd7-2363-4f51-bb70-0c45ec23b218"
   },
   "outputs": [],
   "source": [
    "history = modelU.fit(xTrain, yTrain, epochs = 30, batch_size = 3, validation_data = (xTrain, yTrain), callbacks = [tf.keras.callbacks.EarlyStopping(  patience=5 ), DisplayCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "RfQHWW79HQQ-",
    "outputId": "398632b0-c686-4ad6-efad-507440d27567"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_dice_coef'],label = 'test')\n",
    "plt.plot(history.history['dice_coef'],label='train')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('dice_coef')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VaAiNqnDsxgf"
   },
   "source": [
    "#Распознаём обучающую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sg7q9LAaG6Ph",
    "outputId": "fbb3dab5-931d-4a20-d85a-9c17b643fe57"
   },
   "outputs": [],
   "source": [
    "predu = modelU.predict(xTest)\n",
    "print(predu.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "KPWVBHNLhHir",
    "outputId": "7f23bfc1-6425-4be0-daff-84575f8587d3"
   },
   "outputs": [],
   "source": [
    "n = 1\n",
    "class_ = 1\n",
    "plt.imshow(images[N+n].convert('RGBA'))\n",
    "plt.title('входной кадр')\n",
    "plt.show()\n",
    "plt.imshow(segments[N+n].convert('RGBA'))\n",
    "plt.title('целевая разметка')\n",
    "plt.show()\n",
    "img = yTest[n][:,:,class_]\n",
    "plt.imshow(img.astype(float))\n",
    "plt.title('целевая разметка класс: '+str(class_))\n",
    "plt.show()\n",
    "img = predu[n][:,:,class_]\n",
    "plt.imshow(img.astype(float))\n",
    "plt.title('предиктивная разметка класс: '+str(class_))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZVSciWJaJcT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82sVaHtWa_jj"
   },
   "source": [
    "Что еще делаем:\n",
    "\n",
    "- аугментацию\n",
    "- ищем новые примеры\n",
    "- проверяем разметку\n",
    "- меняем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-P1NeHh4bRSD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "урок_6_Сегментация.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
