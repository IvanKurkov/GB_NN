{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88de3152",
   "metadata": {},
   "source": [
    "## Практическое задание\n",
    "\n",
    "Используем набор примеров fashion-MNIST\n",
    "\n",
    "1.  Опишите - какой результата получен в нейросети в зависимости от:\n",
    "  -  числа нейронов в слое(для 2-хслойной сети), \n",
    "  - числа слоев (2, 3, 5, 10) при близких размерах сети (близкое число тренируемых парметров).\n",
    "  - фиксируйте для тренировочного и тестового набора метрики accuracy.\n",
    "2.  Проверьте работу разных оптимизаторов (SGD, Adam, RMSProp) для одной из моделей п.1.Фиксируйте для тренировочного и тестового набора метрики accuracy.\n",
    "\n",
    "3. Сделайте вывод - что помогло вам улучшить качество классификации в нейросети на тестовом наборе? \n",
    "\n",
    "4. Для одного варианта сетей сформируйте матрицу ошибок по классам. Оцените качество модели по каждому классу отдельно (полнота , точность). Сделайте вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "01d6b733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report,  ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a227ec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_imagef,train_labelf),(test_imagef,test_labelf)=fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f8270b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_imagef.shape)\n",
    "print(test_imagef.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "164363f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imagef = train_imagef.reshape((-1, 784))\n",
    "test_imagef = test_imagef.reshape((-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "353d7085",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imagef = (train_imagef / 127) - 1\n",
    "test_imagef = (test_imagef / 127) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "651d734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential([\n",
    "  Dense(128, activation='tanh', input_shape=(784,)),\n",
    "  Dense(110, activation='tanh'),\n",
    "  Dense(100, activation='tanh'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cde4ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "576246c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_306 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_307 (Dense)           (None, 110)               14190     \n",
      "                                                                 \n",
      " dense_308 (Dense)           (None, 100)               11100     \n",
      "                                                                 \n",
      " dense_309 (Dense)           (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,780\n",
      "Trainable params: 126,780\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32e8e862",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = to_categorical(train_labelf)\n",
    "y_tt = to_categorical(test_labelf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a014c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 1s 972us/step - loss: 0.3086 - accuracy: 0.8887 - val_loss: 0.3514 - val_accuracy: 0.8752\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 1s 949us/step - loss: 0.3016 - accuracy: 0.8900 - val_loss: 0.3505 - val_accuracy: 0.8719\n",
      "313/313 [==============================] - 0s 654us/step - loss: 0.3708 - accuracy: 0.8667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.370841383934021, 0.8666999936103821]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model.\n",
    "model.fit(    \n",
    "  train_imagef[:,:],\n",
    "\n",
    "  y_t[:,:],\n",
    "  epochs=2,\n",
    "  batch_size=32, validation_split=0.2\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate( \n",
    "  test_imagef,\n",
    "  y_tt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c92ba7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "[9 2 1 1 6]\n",
      "[9 2 1 1 6]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict on the first 5 test images.\n",
    "predictions = model.predict(test_imagef[:5])\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(np.argmax(predictions, axis=1))\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(test_labelf[:5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551a8676",
   "metadata": {},
   "source": [
    "### 1. Опишите - какой результат получен в нейросети в зависимости от параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9bb3e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_test_models_1(train_data, train_label, test_data, test_label, optimizer='adam' ,base_neurons=128, add_layers=0 ):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(base_neurons, activation='tanh', input_shape=(784,)))  \n",
    "    for k in range(add_layers):\n",
    "        model.add(Dense(10+(10-k)*10, activation='tanh'))       \n",
    "    model.add(Dense(10, activation='softmax')) \n",
    "\n",
    "    model.compile(\n",
    "      optimizer=optimizer,\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['accuracy'],\n",
    "    )  \n",
    "    \n",
    "    model.fit(    \n",
    "      train_data[:,:],\n",
    "      train_label[:,:],\n",
    "      epochs=2,\n",
    "      batch_size=1024, validation_split=0.2, verbose=0\n",
    "    )\n",
    "    \n",
    "    return f'При параметрах: optimizer = {optimizer}, base_neurons = {base_neurons}, layers = {2 + add_layers} Качество: accuracy = {model.evaluate(test_data, test_label, verbose=0)[1]}'\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c73638f",
   "metadata": {},
   "source": [
    "### 1.1 Числа нейронов в слое(для 2-хслойной сети)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a3098bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "При параметрах: optimizer = adam, base_neurons = 10, layers = 2 Качество: accuracy = 0.7301999926567078\n",
      "При параметрах: optimizer = adam, base_neurons = 20, layers = 2 Качество: accuracy = 0.7806000113487244\n",
      "При параметрах: optimizer = adam, base_neurons = 30, layers = 2 Качество: accuracy = 0.7989000082015991\n",
      "При параметрах: optimizer = adam, base_neurons = 50, layers = 2 Качество: accuracy = 0.809499979019165\n",
      "При параметрах: optimizer = adam, base_neurons = 80, layers = 2 Качество: accuracy = 0.8172000050544739\n",
      "При параметрах: optimizer = adam, base_neurons = 100, layers = 2 Качество: accuracy = 0.8288000226020813\n",
      "При параметрах: optimizer = adam, base_neurons = 128, layers = 2 Качество: accuracy = 0.8209999799728394\n",
      "При параметрах: optimizer = adam, base_neurons = 150, layers = 2 Качество: accuracy = 0.828499972820282\n",
      "При параметрах: optimizer = adam, base_neurons = 180, layers = 2 Качество: accuracy = 0.8299999833106995\n",
      "При параметрах: optimizer = adam, base_neurons = 200, layers = 2 Качество: accuracy = 0.8334000110626221\n",
      "При параметрах: optimizer = adam, base_neurons = 250, layers = 2 Качество: accuracy = 0.8385000228881836\n",
      "При параметрах: optimizer = adam, base_neurons = 350, layers = 2 Качество: accuracy = 0.8324000239372253\n",
      "При параметрах: optimizer = adam, base_neurons = 450, layers = 2 Качество: accuracy = 0.8379999995231628\n",
      "При параметрах: optimizer = adam, base_neurons = 600, layers = 2 Качество: accuracy = 0.8385000228881836\n",
      "При параметрах: optimizer = adam, base_neurons = 800, layers = 2 Качество: accuracy = 0.8384000062942505\n",
      "При параметрах: optimizer = adam, base_neurons = 1000, layers = 2 Качество: accuracy = 0.836899995803833\n"
     ]
    }
   ],
   "source": [
    "num_neurons = [10,20,30,50,80,100,128,150,180,200,250,350,450,600,800,1000]\n",
    "for i in num_neurons:\n",
    "    print(grid_test_models_1(train_imagef, y_t, test_imagef, y_tt, base_neurons = i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5d6101",
   "metadata": {},
   "source": [
    "#### Как видим при увеличении числа нейронов, качество растет"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2981a846",
   "metadata": {},
   "source": [
    "### 1.2 числа слоев (2, 3, 5, 10) при близких размерах сети (близкое число тренируемых парметров)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82f04277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "При параметрах: optimizer = adam, base_neurons = 128, layers = 2 Качество: accuracy = 0.8313999772071838\n",
      "При параметрах: optimizer = adam, base_neurons = 128, layers = 3 Качество: accuracy = 0.8335000276565552\n",
      "При параметрах: optimizer = adam, base_neurons = 128, layers = 4 Качество: accuracy = 0.8328999876976013\n",
      "При параметрах: optimizer = adam, base_neurons = 128, layers = 5 Качество: accuracy = 0.8374000191688538\n",
      "При параметрах: optimizer = adam, base_neurons = 128, layers = 6 Качество: accuracy = 0.8447999954223633\n",
      "При параметрах: optimizer = adam, base_neurons = 128, layers = 7 Качество: accuracy = 0.8392000198364258\n",
      "При параметрах: optimizer = adam, base_neurons = 128, layers = 8 Качество: accuracy = 0.8323000073432922\n",
      "При параметрах: optimizer = adam, base_neurons = 128, layers = 9 Качество: accuracy = 0.8335000276565552\n",
      "При параметрах: optimizer = adam, base_neurons = 128, layers = 10 Качество: accuracy = 0.838100016117096\n",
      "При параметрах: optimizer = adam, base_neurons = 128, layers = 11 Качество: accuracy = 0.826200008392334\n",
      "При параметрах: optimizer = adam, base_neurons = 128, layers = 12 Качество: accuracy = 0.8282999992370605\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    print(grid_test_models_1(train_imagef, y_t, test_imagef, y_tt, add_layers=i ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d619e2",
   "metadata": {},
   "source": [
    "#### Похоже на то, что количество слоев нам не сильно помогло, в какойто момент качество даже стало хуже изначального. Вероятно большое количество ведет к переобучению."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb51345",
   "metadata": {},
   "source": [
    "### 2. Проверьте работу разных оптимизаторов (SGD, Adam, RMSProp) для одной из моделей п.1.Фиксируйте для тренировочного и тестового набора метрики accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6855d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_test_models_2(train_data, train_label, test_data, test_label, optimizer='adam'):\n",
    "    model = Sequential([\n",
    "      Dense(128, activation='tanh', input_shape=(784,)),\n",
    "      Dense(110, activation='tanh'),\n",
    "      Dense(100, activation='tanh'),\n",
    "      Dense(10, activation='softmax'),\n",
    "    ])\n",
    "    model.load_weights('model.h5')\n",
    "    model.compile(\n",
    "      optimizer=optimizer,\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['accuracy'],\n",
    "    )  \n",
    "    \n",
    "    \n",
    "    model.fit(    \n",
    "      train_data[:,:],\n",
    "      train_label[:,:],\n",
    "      epochs=2,\n",
    "      batch_size=1024, validation_split=0.2, verbose=0\n",
    "    )\n",
    "    \n",
    "    return f'При параметрах: optimizer = {optimizer}, base_neurons = {base_neurons}, layers = {2 + add_layers} Качество: accuracy = {model.evaluate(test_data, test_label, verbose=0)[1]}'\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "484c6653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "При параметрах: optimizer = adam, base_neurons = 128, layers = 2 Качество: accuracy = 0.829800009727478\n",
      "При параметрах: optimizer = SGD, base_neurons = 128, layers = 2 Качество: accuracy = 0.7167999744415283\n",
      "При параметрах: optimizer = RMSProp, base_neurons = 128, layers = 2 Качество: accuracy = 0.8104000091552734\n",
      "При параметрах: optimizer = Adagrad, base_neurons = 128, layers = 2 Качество: accuracy = 0.607200026512146\n"
     ]
    }
   ],
   "source": [
    "optimaizers = ['adam', 'SGD', 'RMSProp', 'Adagrad']\n",
    "for i in optimaizers:\n",
    "    print(grid_test_models_1(train_imagef, y_t, test_imagef, y_tt, optimizer = i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b40ee5",
   "metadata": {},
   "source": [
    "#### По всей видимости из перечисленных, Adam справился лучше всех."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec58c426",
   "metadata": {},
   "source": [
    "### 3. Сделайте вывод - что помогло вам улучшить качество классификации в нейросети на тестовом наборе?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ddd9a0",
   "metadata": {},
   "source": [
    "- Из перечисленных выше параметров, наибольший вклад в качество сделал размер слоя, также оптимизатор Adam стал лучшим выбором."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb41f5d",
   "metadata": {},
   "source": [
    "### 4. Сделайте вывод - что помогло вам улучшить качество классификации в нейросети на тестовом наборе?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4298d439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2712268edc0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "      Dense(600, activation='tanh', input_shape=(784,)),      \n",
    "      Dense(10, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "model.compile(\n",
    "      optimizer='adam',\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['accuracy'],\n",
    "    )  \n",
    "    \n",
    "    \n",
    "model.fit(    \n",
    "      train_imagef[:,:],\n",
    "      y_t[:,:],\n",
    "      epochs=35,\n",
    "      batch_size=1024, validation_split=0.2, verbose=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "44a1e0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8831999897956848"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_imagef, y_tt, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "36809481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 917us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_imagef)\n",
    "y_pred_class = np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "39649889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.82      1000\n",
      "           1       0.99      0.97      0.98      1000\n",
      "           2       0.87      0.74      0.80      1000\n",
      "           3       0.91      0.89      0.90      1000\n",
      "           4       0.80      0.83      0.82      1000\n",
      "           5       0.95      0.96      0.95      1000\n",
      "           6       0.63      0.79      0.70      1000\n",
      "           7       0.95      0.94      0.95      1000\n",
      "           8       0.97      0.97      0.97      1000\n",
      "           9       0.96      0.96      0.96      1000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.89      0.88      0.88     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labelf, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "528b4e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = multilabel_confusion_matrix(test_labelf, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "55a244d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x27100307fd0>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay(conf_mat[6]).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ef36a3",
   "metadata": {},
   "source": [
    "#### Видим, что Класс 6 - рубашки, определился хуже всего. Довольно плохая точность, видимо потому, что есть классы очень похожие на этот. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7576dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
