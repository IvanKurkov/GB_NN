{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### В качестве практики возьму датасет персонажей из Симпсонов и буду делать модель классификации.\n",
    "\n",
    "- У нас имеется 42 персонажа.\n",
    "- Классы Очень не сблансированны.\n",
    "- Т.к. классы в любом случае придется балансировать, то метрику будем брать accuracy\n",
    "\n",
    "За основу возьму архитектуру MobileNet V2, т.к. она довольно шустрая, но и в тоже время довольно глубокая. Хотя также есть риск переобучить ее, также потому, что она может быть слишком сложной для такого малого кол-ва данных(размер 1 класса из 42 пимерно 2000 картинок). Попробуем сначала на предобученной модели, попробуем поразмараживать слои, посмотреть на скорость обучения. качество модели. Вероятно придется довольно глубоко размараживать, т.к. обучалась она на фотках imagenet, а тут векорные картинки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:04.892562Z",
     "iopub.status.busy": "2022-06-08T04:09:04.892098Z",
     "iopub.status.idle": "2022-06-08T04:09:07.100463Z",
     "shell.execute_reply": "2022-06-08T04:09:07.099316Z"
    },
    "id": "TqOt6Sv7AsMi"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v77rlkCKW0IJ"
   },
   "source": [
    "## Подготовка данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### В первую очередь данные сбалансируем. Алгоритм следующий:\n",
    "- Смотрим все папки и выясняем максимально чилсло картинок в классе.\n",
    "- Потом по очереди каждый класс смотрим и добавляем аугментированную картинку из имеющихся в классе, до тех пор пока количество не станет равным максимальному классу.\n",
    "\n",
    "*Картинку физически сохраняем на диск в папку с классом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regularisation:\n",
    "    def __init__(self,\n",
    "                 directory='simpsons_dataset/train/'):\n",
    "\n",
    "        self.dir_path = directory\n",
    "        self.directory = os.listdir(path=os.path.join(self.dir_path))\n",
    "\n",
    "        self.min_files = float('inf')\n",
    "        self.max_files = float('-inf')\n",
    "\n",
    "    @staticmethod\n",
    "    def load_image(_file):\n",
    "        image = Image.open(_file)\n",
    "        image.load()\n",
    "\n",
    "        return image, image.size\n",
    "\n",
    "    def transform_image(self, file_):\n",
    "        x, size = self.load_image(file_)\n",
    "\n",
    "        transforms_train = transforms.Compose([\n",
    "            transforms.RandomRotation(degrees=(-15, 15), expand=True),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomResizedCrop(size=size, scale=(0.5, 0.95)),\n",
    "        ])\n",
    "\n",
    "        x = transforms_train(x)\n",
    "\n",
    "        x.save(str(file_)[:-4] + str(randint(1770, 7000)) + \".jpg\", \"JPEG\")\n",
    "\n",
    "    def find_max_min(self):\n",
    "\n",
    "        df = pd.DataFrame(columns=['character', 'total pics'])\n",
    "\n",
    "        for index, folder in enumerate(self.directory):\n",
    "\n",
    "            files_num = len(os.listdir(path=os.path.join(self.dir_path + folder)))\n",
    "\n",
    "            df.loc[index] = {'character': folder, 'total pics': files_num}\n",
    "\n",
    "            if files_num > self.max_files:\n",
    "                self.max_files = files_num\n",
    "\n",
    "            if files_num < self.min_files:\n",
    "                self.min_files = files_num\n",
    "\n",
    "        print(df)\n",
    "\n",
    "        print('--------'\n",
    "              '\\nmax is {0}'\n",
    "              '\\nmin is {1}'.format(self.max_files, self.max_files))\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "    def regularise(self):\n",
    "        self.find_max_min()\n",
    "\n",
    "        if self.max_files != self.min_files:\n",
    "\n",
    "            for folder in tqdm(self.directory):\n",
    "\n",
    "                files_num = len(os.listdir(path=os.path.join(self.dir_path + folder)))\n",
    "                files = os.listdir(path=os.path.join(self.dir_path + folder))\n",
    "\n",
    "                while files_num < self.max_files:\n",
    "\n",
    "                    for file in files:\n",
    "                        files_num = len(os.listdir(path=os.path.join(self.dir_path + folder)))\n",
    "\n",
    "                        if files_num >= self.max_files:\n",
    "                            break\n",
    "\n",
    "                        else:\n",
    "                            path = os.path.join(self.dir_path + folder + '/' + file)\n",
    "                            self.transform_image(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regularisation = Regularisation()\n",
    "regularisation.regularise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GoKGm1duzgk"
   },
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHP9qMJxt2oz"
   },
   "source": [
    "Для загрузки будем использовать утилиту `tf.keras.utils.image_dataset_from_directory`, т.к. загружаем физические картинки с диска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'simpsons_dataset/'\n",
    "img_dir = os.path.join(PATH, 'train')\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "IMG_SIZE = (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:07.107317Z",
     "iopub.status.busy": "2022-06-08T04:09:07.106299Z",
     "iopub.status.idle": "2022-06-08T04:09:11.468058Z",
     "shell.execute_reply": "2022-06-08T04:09:11.467369Z"
    },
    "id": "ro4oYaEmxe4r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 94332 files belonging to 42 classes.\n",
      "Using 75466 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.keras.utils.image_dataset_from_directory(img_dir,\n",
    "                                                            shuffle=True,\n",
    "                                                            batch_size=BATCH_SIZE,\n",
    "                                                            image_size=IMG_SIZE,\n",
    "                                                            label_mode='categorical',\n",
    "                                                            validation_split = 0.2,\n",
    "                                                            subset='training',\n",
    "                                                             seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:11.471656Z",
     "iopub.status.busy": "2022-06-08T04:09:11.471100Z",
     "iopub.status.idle": "2022-06-08T04:09:11.527558Z",
     "shell.execute_reply": "2022-06-08T04:09:11.526941Z"
    },
    "id": "cAvtLwi7_J__"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 94332 files belonging to 42 classes.\n",
      "Using 18866 files for validation.\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(img_dir,\n",
    "                                                                 shuffle=True,\n",
    "                                                                 batch_size=BATCH_SIZE,\n",
    "                                                                 image_size=IMG_SIZE,\n",
    "                                                                 label_mode='categorical',\n",
    "                                                                 validation_split = 0.2,\n",
    "                                                                 subset='validation',\n",
    "                                                                 seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yO1Q2JaW5sIy"
   },
   "source": [
    "Проверим картинки и лейблы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:11.530668Z",
     "iopub.status.busy": "2022-06-08T04:09:11.530160Z",
     "iopub.status.idle": "2022-06-08T04:09:12.004075Z",
     "shell.execute_reply": "2022-06-08T04:09:12.003398Z"
    },
    "id": "K5BeQyKThC_Y"
   },
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[np.argmax(labels[i])])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZqCX_mpV3Mx"
   },
   "source": [
    "Также мы может ощипнуть кусок данных для конечного теста модели. Используем: `tf.data.experimental.cardinality`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:12.014200Z",
     "iopub.status.busy": "2022-06-08T04:09:12.013581Z",
     "iopub.status.idle": "2022-06-08T04:09:12.018889Z",
     "shell.execute_reply": "2022-06-08T04:09:12.018301Z"
    },
    "id": "uFFIYrTFV9RO"
   },
   "outputs": [],
   "source": [
    "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "test_dataset = validation_dataset.take(val_batches // 5)\n",
    "validation_dataset = validation_dataset.skip(val_batches // 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:12.021783Z",
     "iopub.status.busy": "2022-06-08T04:09:12.021350Z",
     "iopub.status.idle": "2022-06-08T04:09:12.025130Z",
     "shell.execute_reply": "2022-06-08T04:09:12.024587Z"
    },
    "id": "Q9pFlFWgBKgH"
   },
   "outputs": [],
   "source": [
    "print('Number of validation batches: %d' % tf.data.experimental.cardinality(train_dataset))\n",
    "print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
    "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MakSrdd--RKg"
   },
   "source": [
    "### Немного магии для ускорения загрузки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22XWC7yjkZu4"
   },
   "source": [
    "Метод для оптимизации загрузки данных в модель при обучении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:12.028200Z",
     "iopub.status.busy": "2022-06-08T04:09:12.027607Z",
     "iopub.status.idle": "2022-06-08T04:09:12.031959Z",
     "shell.execute_reply": "2022-06-08T04:09:12.031379Z"
    },
    "id": "p3UUPdm86LNC"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAywKtuVn8uK"
   },
   "source": [
    "### Стандартизация\n",
    "\n",
    "Так как модель изначально обучалась на входных данных в диапазоне 1, -1, то и наши картинки нужно привести к этому виду. Вообще используя предобученные модели всегда стоит сперва посмотреть, какие данные они ждут на вход. ('[-1, 1]' или '[0, 1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:12.722200Z",
     "iopub.status.busy": "2022-06-08T04:09:12.721772Z",
     "iopub.status.idle": "2022-06-08T04:09:12.725190Z",
     "shell.execute_reply": "2022-06-08T04:09:12.724628Z"
    },
    "id": "cO0HM9JAQUFq"
   },
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnr81qRMzcs5"
   },
   "source": [
    "Также для этого можно использовать простой метод `tf.keras.layers.Rescaling`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:12.728405Z",
     "iopub.status.busy": "2022-06-08T04:09:12.727908Z",
     "iopub.status.idle": "2022-06-08T04:09:12.731432Z",
     "shell.execute_reply": "2022-06-08T04:09:12.730903Z"
    },
    "id": "R2NyJn4KQMux"
   },
   "outputs": [],
   "source": [
    "rescale = tf.keras.layers.Rescaling(1./127.5, offset=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkH-kazQecHB"
   },
   "source": [
    "## Загрузим предобученную модель\n",
    "\n",
    "Если я правильно понял, обычно делают следующим образом: Загружают преобученную модель, заменяют последний слой классификации,\n",
    "и дальше уже \"доучивают\" какуюто часть слоев, на свое усмотрение. Так мы и сделаем, загрузим модель без слоя классификации (include_top=False) и укажем, что веса должны быть из обучения на имеджнете (weights='imagenet'). \n",
    "\n",
    "Таким образом у нас получается, что мы используем предобученную модель для извлечения признаков из нашей картинки, а классифицируем их сами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:12.734577Z",
     "iopub.status.busy": "2022-06-08T04:09:12.734153Z",
     "iopub.status.idle": "2022-06-08T04:09:13.955140Z",
     "shell.execute_reply": "2022-06-08T04:09:13.954497Z"
    },
    "id": "19IQ2gqneqmS"
   },
   "outputs": [],
   "source": [
    "# Загрузка базовой предобученной модели MobileNet V2, не забываем указать размер входящей картинки.\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqcsxoJIEVXZ"
   },
   "source": [
    "###### Т.е. картинка на входе `256x256x3` превращается в тензор признаков `8x8x1280` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:13.958984Z",
     "iopub.status.busy": "2022-06-08T04:09:13.958367Z",
     "iopub.status.idle": "2022-06-08T04:09:14.920251Z",
     "shell.execute_reply": "2022-06-08T04:09:14.919434Z"
    },
    "id": "Y-2LJL0EEUcx"
   },
   "outputs": [],
   "source": [
    "#Посмотрим, чтобы убедиться\n",
    "image_batch, label_batch = next(iter(train_dataset))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlx56nQtfe8Y"
   },
   "source": [
    "## Базовый вариант\n",
    "\n",
    "И так, базовый вариант: просто извлекаем признаки и классифицируем своим классификатором."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnMLieHBCwil"
   },
   "source": [
    "### Замораживаем предобученные веса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fL6upiN3ekS"
   },
   "source": [
    "Важно сделать это до комприляции. Если мы хотим заморозить конкретные слои, то итерируемся по слоям и используем layer.trainable = False. Но т.к. в бозовом варианте мы замораживаем все слои то пишем просто  base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:14.923997Z",
     "iopub.status.busy": "2022-06-08T04:09:14.923396Z",
     "iopub.status.idle": "2022-06-08T04:09:14.929451Z",
     "shell.execute_reply": "2022-06-08T04:09:14.928871Z"
    },
    "id": "OTCJH4bphOeo"
   },
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsNHwpm7BeVM"
   },
   "source": [
    "### Important note about BatchNormalization layers\n",
    "\n",
    "Many models contain `tf.keras.layers.BatchNormalization` layers. This layer is a special case and precautions should be taken in the context of fine-tuning, as shown later in this tutorial. \n",
    "\n",
    "When you set `layer.trainable = False`, the `BatchNormalization` layer will run in inference mode, and will not update its mean and variance statistics. \n",
    "\n",
    "When you unfreeze a model that contains BatchNormalization layers in order to do fine-tuning, you should keep the BatchNormalization layers in inference mode by passing `training = False` when calling the base model. Otherwise, the updates applied to the non-trainable weights will destroy what the model has learned.\n",
    "\n",
    "For more details, see the [Transfer learning guide](https://www.tensorflow.org/guide/keras/transfer_learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:14.932499Z",
     "iopub.status.busy": "2022-06-08T04:09:14.932084Z",
     "iopub.status.idle": "2022-06-08T04:09:15.113577Z",
     "shell.execute_reply": "2022-06-08T04:09:15.112679Z"
    },
    "id": "KpbzSmPkDa-N"
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the base model architecture\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdMRM8YModbk"
   },
   "source": [
    "### Add a classification head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBc31c4tMOdH"
   },
   "source": [
    "To generate predictions from the block of features, average over the spatial `8x8` spatial locations, using a `tf.keras.layers.GlobalAveragePooling2D` layer to convert the features to  a single 1280-element vector per image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:15.216709Z",
     "iopub.status.busy": "2022-06-08T04:09:15.216496Z",
     "iopub.status.idle": "2022-06-08T04:09:15.221037Z",
     "shell.execute_reply": "2022-06-08T04:09:15.220486Z"
    },
    "id": "dLnpMF5KOALm"
   },
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1p0OJBR6dOT"
   },
   "source": [
    "Apply a `tf.keras.layers.Dense` layer to convert these features into a single prediction per image. You don't need an activation function here because this prediction will be treated as a `logit`, or a raw prediction value. Positive numbers predict class 1, negative numbers predict class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:15.224008Z",
     "iopub.status.busy": "2022-06-08T04:09:15.223652Z",
     "iopub.status.idle": "2022-06-08T04:09:15.231049Z",
     "shell.execute_reply": "2022-06-08T04:09:15.230513Z"
    },
    "id": "Wv4afXKj6cVa"
   },
   "outputs": [],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(42)\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXvz-ZkTa9b3"
   },
   "source": [
    "Build a model by chaining together the data augmentation, rescaling, `base_model` and feature extractor layers using the [Keras Functional API](https://www.tensorflow.org/guide/keras/functional). As previously mentioned, use `training=False` as our model contains a `BatchNormalization` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:15.233845Z",
     "iopub.status.busy": "2022-06-08T04:09:15.233434Z",
     "iopub.status.idle": "2022-06-08T04:09:15.567936Z",
     "shell.execute_reply": "2022-06-08T04:09:15.567352Z"
    },
    "id": "DgzQX6Veb2WT"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(256, 256, 3))\n",
    "#x = data_augmentation(inputs)\n",
    "x = preprocess_input(inputs)\n",
    "x = base_model(x, training=True)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0ylJXE_kRLi"
   },
   "source": [
    "### Compile the model\n",
    "\n",
    "Compile the model before training it. Since there are two classes, use the `tf.keras.losses.BinaryCrossentropy` loss with `from_logits=True` since the model provides a linear output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:15.570859Z",
     "iopub.status.busy": "2022-06-08T04:09:15.570646Z",
     "iopub.status.idle": "2022-06-08T04:09:15.581603Z",
     "shell.execute_reply": "2022-06-08T04:09:15.581011Z"
    },
    "id": "RpR8HdyMhukJ"
   },
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:15.584523Z",
     "iopub.status.busy": "2022-06-08T04:09:15.584082Z",
     "iopub.status.idle": "2022-06-08T04:09:15.603581Z",
     "shell.execute_reply": "2022-06-08T04:09:15.603047Z"
    },
    "id": "I8ARiyMFsgbH"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxOcmVr0ydFZ"
   },
   "source": [
    "The 2.5 million parameters in MobileNet are frozen, but there are 1.2 thousand _trainable_ parameters in the Dense layer. These are divided between two `tf.Variable` objects, the weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:15.609251Z",
     "iopub.status.busy": "2022-06-08T04:09:15.608818Z",
     "iopub.status.idle": "2022-06-08T04:09:15.612713Z",
     "shell.execute_reply": "2022-06-08T04:09:15.612194Z"
    },
    "id": "krvBumovycVA"
   },
   "outputs": [],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxvgOYTDSWTx"
   },
   "source": [
    "### Train the model\n",
    "\n",
    "After training for 10 epochs, you should see ~94% accuracy on the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:15.615423Z",
     "iopub.status.busy": "2022-06-08T04:09:15.614930Z",
     "iopub.status.idle": "2022-06-08T04:09:17.445552Z",
     "shell.execute_reply": "2022-06-08T04:09:17.444713Z"
    },
    "id": "Om4O3EESkab1"
   },
   "outputs": [],
   "source": [
    "initial_epochs = 10\n",
    "\n",
    "loss0, accuracy0 = model.evaluate(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:17.448825Z",
     "iopub.status.busy": "2022-06-08T04:09:17.448306Z",
     "iopub.status.idle": "2022-06-08T04:09:17.452142Z",
     "shell.execute_reply": "2022-06-08T04:09:17.451459Z"
    },
    "id": "8cYT1c48CuSd"
   },
   "outputs": [],
   "source": [
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:17.455155Z",
     "iopub.status.busy": "2022-06-08T04:09:17.454668Z",
     "iopub.status.idle": "2022-06-08T04:09:42.627986Z",
     "shell.execute_reply": "2022-06-08T04:09:42.627261Z"
    },
    "id": "JsaRFlZ9B6WK"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hd94CKImf8vi"
   },
   "source": [
    "### Learning curves\n",
    "\n",
    "Let's take a look at the learning curves of the training and validation accuracy/loss when using the MobileNetV2 base model as a fixed feature extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:42.631894Z",
     "iopub.status.busy": "2022-06-08T04:09:42.631207Z",
     "iopub.status.idle": "2022-06-08T04:09:42.808927Z",
     "shell.execute_reply": "2022-06-08T04:09:42.808333Z"
    },
    "id": "53OTCh3jnbwV"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foWMyyUHbc1j"
   },
   "source": [
    "Note: If you are wondering why the validation metrics are clearly better than the training metrics, the main factor is because layers like `tf.keras.layers.BatchNormalization` and `tf.keras.layers.Dropout` affect accuracy during training. They are turned off when calculating validation loss.\n",
    "\n",
    "To a lesser extent, it is also because training metrics report the average for an epoch, while validation metrics are evaluated after the epoch, so validation metrics see a model that has trained slightly longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqwV-CRdS6Nv"
   },
   "source": [
    "## Fine tuning\n",
    "In the feature extraction experiment, you were only training a few layers on top of an MobileNetV2 base model. The weights of the pre-trained network were **not** updated during training.\n",
    "\n",
    "One way to increase performance even further is to train (or \"fine-tune\") the weights of the top layers of the pre-trained model alongside the training of the classifier you added. The training process will force the weights to be tuned from generic feature maps to features associated specifically with the dataset.\n",
    "\n",
    "Note: This should only be attempted after you have trained the top-level classifier with the pre-trained model set to non-trainable. If you add a randomly initialized classifier on top of a pre-trained model and attempt to train all layers jointly, the magnitude of the gradient updates will be too large (due to the random weights from the classifier) and your pre-trained model will forget what it has learned.\n",
    "\n",
    "Also, you should try to fine-tune a small number of top layers rather than the whole MobileNet model. In most convolutional networks, the higher up a layer is, the more specialized it is. The first few layers learn very simple and generic features that generalize to almost all types of images. As you go higher up, the features are increasingly more specific to the dataset on which the model was trained. The goal of fine-tuning is to adapt these specialized features to work with the new dataset, rather than overwrite the generic learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPXnzUK0QonF"
   },
   "source": [
    "### Un-freeze the top layers of the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfxv_ifotQak"
   },
   "source": [
    "All you need to do is unfreeze the `base_model` and set the bottom layers to be un-trainable. Then, you should recompile the model (necessary for these changes to take effect), and resume training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:42.812162Z",
     "iopub.status.busy": "2022-06-08T04:09:42.811938Z",
     "iopub.status.idle": "2022-06-08T04:09:42.817783Z",
     "shell.execute_reply": "2022-06-08T04:09:42.817250Z"
    },
    "id": "4nzcagVitLQm"
   },
   "outputs": [],
   "source": [
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:42.822461Z",
     "iopub.status.busy": "2022-06-08T04:09:42.822027Z",
     "iopub.status.idle": "2022-06-08T04:09:42.827637Z",
     "shell.execute_reply": "2022-06-08T04:09:42.827099Z"
    },
    "id": "-4HgVAacRs5v"
   },
   "outputs": [],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 70\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Uk1dgsxT0IS"
   },
   "source": [
    "### Compile the model\n",
    "\n",
    "As you are training a much larger model and want to readapt the pretrained weights, it is important to use a lower learning rate at this stage. Otherwise, your model could overfit very quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:42.830913Z",
     "iopub.status.busy": "2022-06-08T04:09:42.830355Z",
     "iopub.status.idle": "2022-06-08T04:09:42.839615Z",
     "shell.execute_reply": "2022-06-08T04:09:42.839079Z"
    },
    "id": "NtUnaz0WUDva"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:42.842527Z",
     "iopub.status.busy": "2022-06-08T04:09:42.842019Z",
     "iopub.status.idle": "2022-06-08T04:09:42.862903Z",
     "shell.execute_reply": "2022-06-08T04:09:42.862369Z"
    },
    "id": "WwBWy7J2kZvA"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:42.868426Z",
     "iopub.status.busy": "2022-06-08T04:09:42.867914Z",
     "iopub.status.idle": "2022-06-08T04:09:42.872106Z",
     "shell.execute_reply": "2022-06-08T04:09:42.871551Z"
    },
    "id": "bNXelbMQtonr"
   },
   "outputs": [],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4G5O4jd6TuAG"
   },
   "source": [
    "### Continue training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0foWUN-yDLo_"
   },
   "source": [
    "If you trained to convergence earlier, this step will improve your accuracy by a few percentage points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:09:42.875086Z",
     "iopub.status.busy": "2022-06-08T04:09:42.874653Z",
     "iopub.status.idle": "2022-06-08T04:10:18.786505Z",
     "shell.execute_reply": "2022-06-08T04:10:18.785872Z"
    },
    "id": "ECQLkAsFTlun"
   },
   "outputs": [],
   "source": [
    "fine_tune_epochs = 30\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history.epoch[-1],\n",
    "                         validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfXEmsxQf6eP"
   },
   "source": [
    "Let's take a look at the learning curves of the training and validation accuracy/loss when fine-tuning the last few layers of the MobileNetV2 base model and training the classifier on top of it. The validation loss is much higher than the training loss, so you may get some overfitting.\n",
    "\n",
    "You may also get some overfitting as the new training set is relatively small and similar to the original MobileNetV2 datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNtfNZKlInGT"
   },
   "source": [
    "After fine tuning the model nearly reaches 98% accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:10:18.790464Z",
     "iopub.status.busy": "2022-06-08T04:10:18.789862Z",
     "iopub.status.idle": "2022-06-08T04:10:18.793534Z",
     "shell.execute_reply": "2022-06-08T04:10:18.792967Z"
    },
    "id": "PpA8PlpQKygw"
   },
   "outputs": [],
   "source": [
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:10:18.796432Z",
     "iopub.status.busy": "2022-06-08T04:10:18.795894Z",
     "iopub.status.idle": "2022-06-08T04:10:19.013485Z",
     "shell.execute_reply": "2022-06-08T04:10:19.012826Z"
    },
    "id": "chW103JUItdk"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.ylim([0.8, 1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6cWgjgfrsn5"
   },
   "source": [
    "### Evaluation and prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSXH7PRMxOi5"
   },
   "source": [
    "Finally you can verify the performance of the model on new data using test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:10:19.016538Z",
     "iopub.status.busy": "2022-06-08T04:10:19.016325Z",
     "iopub.status.idle": "2022-06-08T04:10:19.172751Z",
     "shell.execute_reply": "2022-06-08T04:10:19.172059Z"
    },
    "id": "2KyNhagHwfar"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print('Test accuracy :', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UjS5ukZfOcR"
   },
   "source": [
    "And now you are all set to use this model to predict if your pet is a cat or dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T04:10:19.176091Z",
     "iopub.status.busy": "2022-06-08T04:10:19.175518Z",
     "iopub.status.idle": "2022-06-08T04:10:20.286556Z",
     "shell.execute_reply": "2022-06-08T04:10:20.285934Z"
    },
    "id": "RUNoQNgtfNgt"
   },
   "outputs": [],
   "source": [
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch)\n",
    "print('Predictions:\\n', predictions)\n",
    "# Apply a sigmoid since our model returns logits\n",
    "#predictions = tf.nn.sigmoid(predictions)\n",
    "#predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "#print('Predictions:\\n', predictions.numpy())\n",
    "#print('Labels:\\n', label_batch)\n",
    "\n",
    "#plt.figure(figsize=(10, 10))\n",
    "#for i in range(30):\n",
    "#  ax = plt.subplot(3, 10, i + 1)\n",
    "#  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "#  plt.title(class_names[predictions[i]])\n",
    "#  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = image.load_img('test.jpg', target_size = IMG_SIZE)\n",
    "t = image.img_to_array(t)\n",
    "tt = []\n",
    "tt.append(t)\n",
    "tt = np.array(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p >0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TZTwG7nhm0C"
   },
   "source": [
    "## Summary\n",
    "\n",
    "* **Using a pre-trained model for feature extraction**:  When working with a small dataset, it is a common practice to take advantage of features learned by a model trained on a larger dataset in the same domain. This is done by instantiating the pre-trained model and adding a fully-connected classifier on top. The pre-trained model is \"frozen\" and only the weights of the classifier get updated during training.\n",
    "In this case, the convolutional base extracted all the features associated with each image and you just trained a classifier that determines the image class given that set of extracted features.\n",
    "\n",
    "* **Fine-tuning a pre-trained model**: To further improve performance, one might want to repurpose the top-level layers of the pre-trained models to the new dataset via fine-tuning.\n",
    "In this case, you tuned your weights such that your model learned high-level features specific to the dataset. This technique is usually recommended when the training dataset is large and very similar to the original dataset that the pre-trained model was trained on.\n",
    "\n",
    "To learn more, visit the [Transfer learning guide](https://www.tensorflow.org/guide/keras/transfer_learning).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "transfer_learning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
